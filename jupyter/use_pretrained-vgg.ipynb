{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose\n",
    "from keras.layers import MaxPooling2D, UpSampling2D, AveragePooling2D\n",
    "from keras.layers import BatchNormalization, Activation, concatenate, Lambda, add, Dropout\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('../../render/210324/exr/img-0-diffuse.exr', -1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[29.796875, 29.796875, 29.796875],\n",
       "        [29.15625 , 29.15625 , 29.15625 ],\n",
       "        [28.609375, 28.609375, 28.609375],\n",
       "        [28.078125, 28.078125, 28.078125],\n",
       "        [27.359375, 27.359375, 27.359375]],\n",
       "\n",
       "       [[29.71875 , 29.71875 , 29.71875 ],\n",
       "        [29.265625, 29.265625, 29.265625],\n",
       "        [28.53125 , 28.53125 , 28.53125 ],\n",
       "        [27.921875, 27.921875, 27.921875],\n",
       "        [27.53125 , 27.53125 , 27.53125 ]],\n",
       "\n",
       "       [[29.765625, 29.765625, 29.765625],\n",
       "        [29.265625, 29.265625, 29.265625],\n",
       "        [28.59375 , 28.59375 , 28.59375 ],\n",
       "        [27.796875, 27.796875, 27.796875],\n",
       "        [27.21875 , 27.21875 , 27.21875 ]],\n",
       "\n",
       "       [[30.      , 30.      , 30.      ],\n",
       "        [29.15625 , 29.15625 , 29.15625 ],\n",
       "        [28.453125, 28.453125, 28.453125],\n",
       "        [27.953125, 27.953125, 27.953125],\n",
       "        [28.171875, 28.171875, 28.171875]],\n",
       "\n",
       "       [[29.6875  , 29.6875  , 29.6875  ],\n",
       "        [29.      , 29.      , 29.      ],\n",
       "        [28.234375, 28.234375, 28.234375],\n",
       "        [27.765625, 27.765625, 27.765625],\n",
       "        [27.28125 , 27.28125 , 27.28125 ]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[300:305, 300:305, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kodai Tokieda\\Anaconda3\\envs\\lab_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(512,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_block(x, ch):\n",
    "    def base_block(x):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        # x = Dropout(rate=drop_rate)(x)\n",
    "        x = Conv2D(ch, (3, 3), padding='same')(x)\n",
    "        return x\n",
    "\n",
    "    x = base_block(x)\n",
    "    x = base_block(x)\n",
    "    return x\n",
    "\n",
    "def decode_block(x, c, ch):\n",
    "    ch = ch\n",
    "    def base_block(x):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        # x = Dropout(rate=drop_rate)(x)\n",
    "        x = Conv2DTranspose(ch, (3, 3), padding='same')(x)\n",
    "        return x\n",
    "\n",
    "    x = Conv2DTranspose(ch, (3, 3), padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = concatenate([x, c])\n",
    "\n",
    "    x = base_block(x)\n",
    "    x = base_block(x)\n",
    "    return x\n",
    "\n",
    "batch_shape = (512, 512)\n",
    "ch_num = 3\n",
    "\n",
    "input_batch = Input(shape=(*batch_shape, ch_num))\n",
    "e0 = Conv2D(8, (1, 1), padding='same')(input_batch)\n",
    "e0 = Activation('relu')(e0)\n",
    "\n",
    "e0 = encode_block(e0, 16)\n",
    "\n",
    "e1 = AveragePooling2D((2, 2))(e0)\n",
    "e1 = encode_block(e1, 32)\n",
    "\n",
    "e2 = AveragePooling2D((2, 2))(e1)\n",
    "e2 = encode_block(e2, 64)\n",
    "\n",
    "e3 = AveragePooling2D((2, 2))(e2)\n",
    "e3 = encode_block(e3, 128)\n",
    "\n",
    "d2 = decode_block(e3, e2, 64)\n",
    "d1 = decode_block(d2, e1, 32)\n",
    "d0 = decode_block(d1, e0, 16)\n",
    "\n",
    "output_batch = Conv2D(ch_num, (1, 1), padding='same')(d0)\n",
    "\n",
    "model = Model(input_batch, output_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model = Model(vgg_model.inputs, vgg_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = img[None, ...]\n",
    "feature = loss_model.predict(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 16, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_layers = [1,2,9,10,17,18]\n",
    "selected_outputs = [vgg_model.layers[i].output for i in selected_layers]\n",
    "multi_loss_model = Model(vgg_model.inputs, selected_outputs)\n",
    "multi_loss_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_feature = multi_loss_model.predict(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 64)\n",
      "(1, 512, 512, 64)\n",
      "(1, 128, 128, 256)\n",
      "(1, 64, 64, 256)\n",
      "(1, 32, 32, 512)\n",
      "(1, 16, 16, 512)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(multi_feature)):\n",
    "    print(multi_feature[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
